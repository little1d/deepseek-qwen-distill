from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch
import gradio as gr
import time


# æ¨¡å‹åŠ è½½ä¼˜åŒ–å‡½æ•°  æ ¹æ®ä½ æƒ³æµ‹è¯•çš„ stage ä¸åŒï¼Œæ¥é€‰æ‹©æ¨¡å‹æ–‡ä»¶è·¯å¾„
def load_chem_model():
    try:
        model_id_stage_1 = "/home/bingxing2/ailab/yangzhuo/deepseek-qwen-distill/qwen2.5-3b-deepseek-finetuned-final-stage1"
        model = AutoModelForCausalLM.from_pretrained(
            model_id_stage_1,
            device_map="auto",
            torch_dtype=torch.float16,
        )
        tokenizer = AutoTokenizer.from_pretrained(
            model_id_stage_1,
        )
        model.resize_token_embeddings(len(tokenizer))
        print("æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model, tokenizer
    except Exception as e:
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}") from e


# åˆå§‹åŒ–ç»„ä»¶
try:
    model, tokenizer = load_chem_model()
    chat_pipeline = pipeline(
        "text-generation", model=model, tokenizer=tokenizer, device_map="auto"
    )
except Exception as e:
    print(f"åˆå§‹åŒ–é”™è¯¯: {e}")
    exit(1)

# åŒ–å­¦ä¸“ä¸šå¯¹è¯æ¨¡æ¿ç³»ç»Ÿ
CHEM_SYSTEM_PROMPT = """<|im_start|>system
You are ChemReasoner, a professional chemistry AI assistant with the following capabilities:
Parse molecular SMILES structures.
Predict compound properties (such as ADME and toxicity).
Design chemical synthesis routes.
Analyze reaction mechanisms.
Retrieve literature data.
Please answer chemistry - related questions in a professional yet accessible manner.<|im_end|>
"""


def build_chemistry_prompt(history):
    prompt = CHEM_SYSTEM_PROMPT
    for turn in history:
        role = "user" if turn[0] else "assistant"
        content = turn[1].replace("<|im_end|>", "").strip()
        prompt += f"<|im_start|>{role}\n{content}<|im_end|>\n"
    prompt += "<|im_start|>assistant\n"
    return prompt


# åŒ–å­¦å“åº”ç”Ÿæˆå¤„ç†å™¨
def chemical_respond(message, history, temperature, max_tokens):
    start_time = time.time()

    try:
        # æ„å»ºå®Œæ•´å¯¹è¯å†å²
        full_history = []
        for h in history:
            full_history.extend([(True, h[0]), (False, h[1])])
        full_history.append((True, message))

        # ç”ŸæˆåŒ–å­¦ä¸“ä¸šprompt
        generation_prompt = build_chemistry_prompt(full_history)

        # ç”Ÿæˆå‚æ•°é…ç½®
        generate_kwargs = {
            "max_new_tokens": min(int(max_tokens), 5000),
            "temperature": max(0.1, min(float(temperature), 1.0)),
            "do_sample": True,
            "top_p": 0.9,
            "repetition_penalty": 1.1,
            "eos_token_id": tokenizer.eos_token_id,
        }

        # æ‰§è¡Œç”Ÿæˆ
        output = chat_pipeline(generation_prompt, **generate_kwargs)
        response = output[0]["generated_text"][len(generation_prompt) :]

        # æ¸…ç†å“åº”å¹¶æ·»åŠ åŒ–å­¦æ ¼å¼å¤„ç†
        response = response.split("<|im_end|>")[0].strip()
        response = format_chemical_response(response)

        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        gen_time = time.time() - start_time
        print(f"ç”Ÿæˆè€—æ—¶: {gen_time:.2f}s | Tokens: {len(response.split())}")

        return response

    except Exception as e:
        print(f"ç”Ÿæˆé”™è¯¯: {e}")
        return "âš ï¸ç”Ÿæˆé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ ¼å¼æˆ–è°ƒæ•´å‚æ•°é‡è¯•"


# åŒ–å­¦å“åº”æ ¼å¼åŒ–
def format_chemical_response(text):
    # æ ‡è®°åŒ–å­¦æœ¯è¯­é«˜äº®
    chem_keywords = ["SMILES", "ADME", "logP", "pKa", "IC50", "EC50"]
    for word in chem_keywords:
        text = text.replace(word, f"**{word}**")
        # æ·»åŠ åŒ–å­¦å¼æ’ç‰ˆ
    text = text.replace("->", "â†’")  # æ›¿æ¢ååº”ç®­å¤´
    # SMILESæ ¼å¼å¤„ç†
    if "SMILES" in text:
        parts = text.split("SMILES:", 1)
        text = parts[0] + f"SMILES:\n`{parts[1].strip()}`" if len(parts) > 1 else text
    # åŒ–å­¦å¼ä¸‹æ ‡å¤„ç†
    chemical_formats = {
        "H2O": "Hâ‚‚O",
        "CO2": "COâ‚‚",
        "CH3OH": "CHâ‚ƒOH",
        # æ·»åŠ æ›´å¤šå¸¸è§åŒ–å­¦å¼è½¬æ¢
    }
    for orig, fmt in chemical_formats.items():
        text = text.replace(orig, fmt)
    return text


# åˆ›å»ºä¸“ä¸šåŒ–å­¦ç•Œé¢
with gr.Blocks(
    theme=gr.themes.Soft(), css=".gradio-container {max-width: 800px}"
) as demo:
    gr.Markdown("# ğŸ§ª ChemReasoner - ä¸“ä¸šåŒ–å­¦æ¨ç†åŠ©æ‰‹")
    gr.Markdown("### åŸºäºQwen2.5-3B-DeepSeekæ¨¡å‹çš„ä¸“ä¸šåŒ–å­¦AIåŠ©æ‰‹")

    with gr.Row():
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(label="å¯¹è¯è®°å½•", height=500)
            msg = gr.Textbox(
                label="è¾“å…¥åŒ–å­¦é—®é¢˜", placeholder="è¾“å…¥SMILESç»“æ„æˆ–åŒ–å­¦é—®é¢˜..."
            )
            with gr.Row():
                submit_btn = gr.Button("ğŸš€ æäº¤")
                clear_btn = gr.Button("ğŸ§¹ æ¸…ç©º")
        with gr.Column(scale=1):
            temperature = gr.Slider(
                0.1, 1.0, value=0.7, label="åˆ›æ„æ¸©åº¦", info="å€¼è¶Šé«˜è¶Šæœ‰åˆ›æ„"
            )
            max_tokens = gr.Slider(
                100, 5000, value=2000, step=100, label="æœ€å¤§ç”Ÿæˆé•¿åº¦"
            )
            gr.Examples(
                examples=[
                    ["What is the IUPAC name of CCO?"],
                    ["Design a synthetic route from benzoic acid to aspirin."],
                    ["Predict the logP value of C(C(=O)O)N."],
                    ["Explain the mechanism of SN2 reaction."],
                ],
                inputs=msg,
                label="Chemistry Examples",
            )

    # äº¤äº’é€»è¾‘
    submit_btn.click(
        fn=chemical_respond,
        inputs=[msg, chatbot, temperature, max_tokens],
        outputs=[msg, chatbot],
        queue=True,
    )
    msg.submit(
        fn=chemical_respond,
        inputs=[msg, chatbot, temperature, max_tokens],
        outputs=[msg, chatbot],
        queue=True,
    )
    clear_btn.click(lambda: None, None, chatbot, queue=False)
# å¯åŠ¨é…ç½®
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=10003,
        share=True,
        favicon_path="./chem_icon.svg",  # åŒ–å­¦ä¸»é¢˜å›¾æ ‡
    )
